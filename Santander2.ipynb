{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santander2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogut77/LogisticRegression/blob/master/Santander2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5Oy-FBOFe7K1",
        "colab_type": "code",
        "outputId": "f265e9d9-f2a7-46ee-deaa-5ef1d954b847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "   "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LUNC1WewPKlH",
        "colab_type": "code",
        "outputId": "0b74ab14-d05d-414f-b90a-b04c34951985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yhf-eYWiPnld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/content/.kaggle/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZNFh7SvFQwCN",
        "colab_type": "code",
        "outputId": "2813ebb5-72e7-4289-b232-e5d36f6caf4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/santander/'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv.zip  test.csv.zip  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L9oluC0eQW1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "token = {\"username\":\"hulisi\",\"key\":\"4163066d5cebf9ad2cc14e4ef9a71c3c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSzSmL1DQgzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp '/content/.kaggle/kaggle.json' ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uDK6cUrvQnbp",
        "colab_type": "code",
        "outputId": "2bd75c2e-290b-443a-fe9f-5f1badf28577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle config set -n path -v{/content/}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content/}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FhGz7PSuRzi9",
        "colab_type": "code",
        "outputId": "26df649b-6b73-46cd-f256-d186cce3274b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c santander-customer-transaction-prediction -p /content/"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading train.csv.zip to /content\n",
            " 99% 121M/122M [00:02<00:00, 28.7MB/s]\n",
            "100% 122M/122M [00:02<00:00, 44.6MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/463k [00:00<?, ?B/s]\n",
            "100% 463k/463k [00:00<00:00, 106MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 98% 119M/122M [00:00<00:00, 144MB/s]\n",
            "100% 122M/122M [00:00<00:00, 141MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "05UOpdKESEml",
        "colab_type": "code",
        "outputId": "44b900d8-0cb9-4813-fe60-b6a36f9a54ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t     sample_submission.csv.zip\ttest.csv.zip\n",
            "sample_data  santander\t\t\ttrain.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQbQ0FXT77Uz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "4b82bcf6-9872-4792-b926-42a630a0be18"
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "shkspr=urllib.request.urlretrieve('/content/santander/test.csv.zip','/content/drive/My Drive/santander/test.csv.zip')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-60bff6b099e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshkspr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/santander/test.csv.zip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/My Drive/santander/test.csv.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# accept a URL or a Request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    327\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                  method=None):\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown url type: '/content/santander/test.csv.zip'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DLmY8-q6S8xL",
        "colab_type": "code",
        "outputId": "98149039-6ceb-49c9-cd10-39379f7e4e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "3 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4NXCJ1EdTEXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "d = pd.read_csv('/content/train.csv')\n",
        "d.to_csv('/content/drive/My Drive/Santander/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ncrKFE1gA7WA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "e = pd.read_csv('/content/test.csv')\n",
        "e.to_csv('/content/drive/My Drive/Santander/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AH6K2fBcFB-t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "f = pd.read_csv('/content/sample_submission.csv')\n",
        "f.to_csv('/content/drive/My Drive/Santander/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UT7LM27dV0o4",
        "colab_type": "code",
        "outputId": "2418906b-3398-4afe-d8e3-f016d327f9f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "cell_type": "code",
      "source": [
        "2 = pd.read_csv('/content/drive/My Drive/Santander/train.csv')\n",
        "d2.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>train_2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>train_4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 203 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
              "0           0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
              "1           1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
              "2           2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
              "3           3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
              "4           4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
              "\n",
              "    var_5   var_6   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
              "0 -9.2834  5.1187   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
              "1  7.0433  5.6208   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
              "2 -9.0837  6.9427   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
              "3 -1.8361  5.8428   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
              "4  2.4486  5.9405   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
              "\n",
              "   var_195  var_196  var_197  var_198  var_199  \n",
              "0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
              "2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 203 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "W61QeEDXCFO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1058
        },
        "outputId": "9f87b9c7-5970-4c1a-cffd-3d8bc3fff01a"
      },
      "cell_type": "code",
      "source": [
        "d2.dtypes"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0      int64\n",
              "ID_code        object\n",
              "target          int64\n",
              "var_0         float64\n",
              "var_1         float64\n",
              "var_2         float64\n",
              "var_3         float64\n",
              "var_4         float64\n",
              "var_5         float64\n",
              "var_6         float64\n",
              "var_7         float64\n",
              "var_8         float64\n",
              "var_9         float64\n",
              "var_10        float64\n",
              "var_11        float64\n",
              "var_12        float64\n",
              "var_13        float64\n",
              "var_14        float64\n",
              "var_15        float64\n",
              "var_16        float64\n",
              "var_17        float64\n",
              "var_18        float64\n",
              "var_19        float64\n",
              "var_20        float64\n",
              "var_21        float64\n",
              "var_22        float64\n",
              "var_23        float64\n",
              "var_24        float64\n",
              "var_25        float64\n",
              "var_26        float64\n",
              "               ...   \n",
              "var_170       float64\n",
              "var_171       float64\n",
              "var_172       float64\n",
              "var_173       float64\n",
              "var_174       float64\n",
              "var_175       float64\n",
              "var_176       float64\n",
              "var_177       float64\n",
              "var_178       float64\n",
              "var_179       float64\n",
              "var_180       float64\n",
              "var_181       float64\n",
              "var_182       float64\n",
              "var_183       float64\n",
              "var_184       float64\n",
              "var_185       float64\n",
              "var_186       float64\n",
              "var_187       float64\n",
              "var_188       float64\n",
              "var_189       float64\n",
              "var_190       float64\n",
              "var_191       float64\n",
              "var_192       float64\n",
              "var_193       float64\n",
              "var_194       float64\n",
              "var_195       float64\n",
              "var_196       float64\n",
              "var_197       float64\n",
              "var_198       float64\n",
              "var_199       float64\n",
              "Length: 203, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "cziuHOHNCKH1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d2.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYbmtKhrCA4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "d2.to_csv('/content/drive/My Drive/Santander/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-_v8VFUBfpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "97f7a99d-2dac-4f5d-f2f1-75557a9678e7"
      },
      "cell_type": "code",
      "source": [
        "d2.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-ab694e958fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: labels ['Unnamed: 0'] not contained in axis"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "d7O3VgxcDt9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "a87e4efb-48a5-4470-948d-615b83aa5915"
      },
      "cell_type": "code",
      "source": [
        "d2.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 202 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
              "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
              "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
              "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
              "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
              "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
              "\n",
              "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
              "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
              "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
              "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
              "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
              "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
              "\n",
              "   var_196  var_197  var_198  var_199  \n",
              "0   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   8.1267   8.7889  18.3560   1.9518  \n",
              "2  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 202 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "sWuUSK95OoZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dx=d2.iloc[:,2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVvhYw69SHmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dy=d2.iloc[:,1:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YY41XFFOthp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "32900db4-e464-4627-f7e0-952c4d7479f5"
      },
      "cell_type": "code",
      "source": [
        "dx.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>-4.9200</td>\n",
              "      <td>5.7470</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>3.1468</td>\n",
              "      <td>8.0851</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>-4.9193</td>\n",
              "      <td>5.9525</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>-5.8609</td>\n",
              "      <td>8.2450</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>6.2654</td>\n",
              "      <td>7.6784</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
              "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
              "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
              "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
              "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
              "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
              "\n",
              "    var_9   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
              "0  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
              "1  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
              "2  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
              "3  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
              "4  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
              "\n",
              "   var_196  var_197  var_198  var_199  \n",
              "0   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   8.1267   8.7889  18.3560   1.9518  \n",
              "2  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "Q2-da6OJOWZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()  \n",
        "dn = sc.fit_transform(dx) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtrfQ3qgOmkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "e69417c7-7713-48ac-9b34-9749534b3a49"
      },
      "cell_type": "code",
      "source": [
        "dn = pd.DataFrame(dn)\n",
        "dn.shape\n",
        "dn.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.577102</td>\n",
              "      <td>-1.273737</td>\n",
              "      <td>0.451707</td>\n",
              "      <td>-0.833709</td>\n",
              "      <td>0.235571</td>\n",
              "      <td>-0.536430</td>\n",
              "      <td>-0.334926</td>\n",
              "      <td>0.608751</td>\n",
              "      <td>-1.561580</td>\n",
              "      <td>-1.473796</td>\n",
              "      <td>...</td>\n",
              "      <td>0.263374</td>\n",
              "      <td>-1.149158</td>\n",
              "      <td>0.817469</td>\n",
              "      <td>-0.411013</td>\n",
              "      <td>0.168705</td>\n",
              "      <td>-1.578117</td>\n",
              "      <td>1.022131</td>\n",
              "      <td>-0.373968</td>\n",
              "      <td>-1.026398</td>\n",
              "      <td>0.214135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.269959</td>\n",
              "      <td>-0.622138</td>\n",
              "      <td>1.190360</td>\n",
              "      <td>-0.688846</td>\n",
              "      <td>0.790975</td>\n",
              "      <td>1.539900</td>\n",
              "      <td>0.244461</td>\n",
              "      <td>-0.003525</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.419300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.966611</td>\n",
              "      <td>0.093605</td>\n",
              "      <td>0.443623</td>\n",
              "      <td>1.908764</td>\n",
              "      <td>-0.817594</td>\n",
              "      <td>1.522342</td>\n",
              "      <td>1.067654</td>\n",
              "      <td>-0.129400</td>\n",
              "      <td>0.825417</td>\n",
              "      <td>0.505685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.681113</td>\n",
              "      <td>-0.276066</td>\n",
              "      <td>0.516988</td>\n",
              "      <td>0.536516</td>\n",
              "      <td>-0.305477</td>\n",
              "      <td>-0.511033</td>\n",
              "      <td>1.769839</td>\n",
              "      <td>-0.564749</td>\n",
              "      <td>-1.561370</td>\n",
              "      <td>-1.307408</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072093</td>\n",
              "      <td>0.777997</td>\n",
              "      <td>-0.174131</td>\n",
              "      <td>-0.412316</td>\n",
              "      <td>1.151591</td>\n",
              "      <td>2.297370</td>\n",
              "      <td>-1.617906</td>\n",
              "      <td>-0.695141</td>\n",
              "      <td>-0.381449</td>\n",
              "      <td>0.356681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.125158</td>\n",
              "      <td>-0.129426</td>\n",
              "      <td>-0.667575</td>\n",
              "      <td>0.195355</td>\n",
              "      <td>0.927992</td>\n",
              "      <td>0.410672</td>\n",
              "      <td>0.500633</td>\n",
              "      <td>-0.474201</td>\n",
              "      <td>-1.843910</td>\n",
              "      <td>0.548767</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270216</td>\n",
              "      <td>-0.891456</td>\n",
              "      <td>-0.818468</td>\n",
              "      <td>-0.478548</td>\n",
              "      <td>1.607869</td>\n",
              "      <td>-0.789517</td>\n",
              "      <td>-0.959020</td>\n",
              "      <td>1.501744</td>\n",
              "      <td>0.697118</td>\n",
              "      <td>-0.543502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.277303</td>\n",
              "      <td>0.035610</td>\n",
              "      <td>0.817683</td>\n",
              "      <td>-0.077829</td>\n",
              "      <td>0.738607</td>\n",
              "      <td>0.955574</td>\n",
              "      <td>0.613372</td>\n",
              "      <td>0.791544</td>\n",
              "      <td>1.794753</td>\n",
              "      <td>0.090006</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.036191</td>\n",
              "      <td>0.688988</td>\n",
              "      <td>-1.405987</td>\n",
              "      <td>1.468536</td>\n",
              "      <td>-1.501101</td>\n",
              "      <td>-0.958473</td>\n",
              "      <td>0.297627</td>\n",
              "      <td>0.645537</td>\n",
              "      <td>0.706318</td>\n",
              "      <td>-0.525375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.577102 -1.273737  0.451707 -0.833709  0.235571 -0.536430 -0.334926   \n",
              "1  0.269959 -0.622138  1.190360 -0.688846  0.790975  1.539900  0.244461   \n",
              "2 -0.681113 -0.276066  0.516988  0.536516 -0.305477 -0.511033  1.769839   \n",
              "3  0.125158 -0.129426 -0.667575  0.195355  0.927992  0.410672  0.500633   \n",
              "4 -0.277303  0.035610  0.817683 -0.077829  0.738607  0.955574  0.613372   \n",
              "\n",
              "        7         8         9      ...          190       191       192  \\\n",
              "0  0.608751 -1.561580 -1.473796    ...     0.263374 -1.149158  0.817469   \n",
              "1 -0.003525  0.858974  0.419300    ...     0.966611  0.093605  0.443623   \n",
              "2 -0.564749 -1.561370 -1.307408    ...    -0.072093  0.777997 -0.174131   \n",
              "3 -0.474201 -1.843910  0.548767    ...     0.270216 -0.891456 -0.818468   \n",
              "4  0.791544  1.794753  0.090006    ...    -1.036191  0.688988 -1.405987   \n",
              "\n",
              "        193       194       195       196       197       198       199  \n",
              "0 -0.411013  0.168705 -1.578117  1.022131 -0.373968 -1.026398  0.214135  \n",
              "1  1.908764 -0.817594  1.522342  1.067654 -0.129400  0.825417  0.505685  \n",
              "2 -0.412316  1.151591  2.297370 -1.617906 -0.695141 -0.381449  0.356681  \n",
              "3 -0.478548  1.607869 -0.789517 -0.959020  1.501744  0.697118 -0.543502  \n",
              "4  1.468536 -1.501101 -0.958473  0.297627  0.645537  0.706318 -0.525375  \n",
              "\n",
              "[5 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "lBpR2xqBR_Y6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#merge dx with dy\n",
        "\n",
        "dt=pd.concat([dy, dn], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WAyHXXUaUc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "f3f5ea67-7730-4306-8f46-f5231e51b499"
      },
      "cell_type": "code",
      "source": [
        "dt.head(2)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.577102</td>\n",
              "      <td>-1.273737</td>\n",
              "      <td>0.451707</td>\n",
              "      <td>-0.833709</td>\n",
              "      <td>0.235571</td>\n",
              "      <td>-0.53643</td>\n",
              "      <td>-0.334926</td>\n",
              "      <td>0.608751</td>\n",
              "      <td>-1.561580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.263374</td>\n",
              "      <td>-1.149158</td>\n",
              "      <td>0.817469</td>\n",
              "      <td>-0.411013</td>\n",
              "      <td>0.168705</td>\n",
              "      <td>-1.578117</td>\n",
              "      <td>1.022131</td>\n",
              "      <td>-0.373968</td>\n",
              "      <td>-1.026398</td>\n",
              "      <td>0.214135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.269959</td>\n",
              "      <td>-0.622138</td>\n",
              "      <td>1.190360</td>\n",
              "      <td>-0.688846</td>\n",
              "      <td>0.790975</td>\n",
              "      <td>1.53990</td>\n",
              "      <td>0.244461</td>\n",
              "      <td>-0.003525</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>...</td>\n",
              "      <td>0.966611</td>\n",
              "      <td>0.093605</td>\n",
              "      <td>0.443623</td>\n",
              "      <td>1.908764</td>\n",
              "      <td>-0.817594</td>\n",
              "      <td>1.522342</td>\n",
              "      <td>1.067654</td>\n",
              "      <td>-0.129400</td>\n",
              "      <td>0.825417</td>\n",
              "      <td>0.505685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         0         1         2         3         4        5  \\\n",
              "0       0 -0.577102 -1.273737  0.451707 -0.833709  0.235571 -0.53643   \n",
              "1       0  0.269959 -0.622138  1.190360 -0.688846  0.790975  1.53990   \n",
              "\n",
              "          6         7         8    ...          190       191       192  \\\n",
              "0 -0.334926  0.608751 -1.561580    ...     0.263374 -1.149158  0.817469   \n",
              "1  0.244461 -0.003525  0.858974    ...     0.966611  0.093605  0.443623   \n",
              "\n",
              "        193       194       195       196       197       198       199  \n",
              "0 -0.411013  0.168705 -1.578117  1.022131 -0.373968 -1.026398  0.214135  \n",
              "1  1.908764 -0.817594  1.522342  1.067654 -0.129400  0.825417  0.505685  \n",
              "\n",
              "[2 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "0I6JrfxaWEat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dt, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvT1-3aYOUUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "3fdacd69-39a9-4c81-c4d1-3f6c47b7759c"
      },
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.099594</td>\n",
              "      <td>-0.001368</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>-0.001077</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>-0.001045</td>\n",
              "      <td>-0.001867</td>\n",
              "      <td>-0.002470</td>\n",
              "      <td>0.000271</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>-0.001276</td>\n",
              "      <td>0.000912</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>-0.002370</td>\n",
              "      <td>-0.000563</td>\n",
              "      <td>-0.001272</td>\n",
              "      <td>0.001376</td>\n",
              "      <td>-0.000204</td>\n",
              "      <td>0.000563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.299459</td>\n",
              "      <td>1.000199</td>\n",
              "      <td>0.999324</td>\n",
              "      <td>0.999711</td>\n",
              "      <td>1.001524</td>\n",
              "      <td>0.999005</td>\n",
              "      <td>1.000244</td>\n",
              "      <td>0.998705</td>\n",
              "      <td>1.000824</td>\n",
              "      <td>1.000738</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999272</td>\n",
              "      <td>0.999214</td>\n",
              "      <td>0.999513</td>\n",
              "      <td>0.999254</td>\n",
              "      <td>0.999717</td>\n",
              "      <td>1.000286</td>\n",
              "      <td>1.000277</td>\n",
              "      <td>1.000812</td>\n",
              "      <td>1.000201</td>\n",
              "      <td>0.999229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.378739</td>\n",
              "      <td>-3.312510</td>\n",
              "      <td>-3.255758</td>\n",
              "      <td>-3.345903</td>\n",
              "      <td>-3.698703</td>\n",
              "      <td>-3.496937</td>\n",
              "      <td>-3.532923</td>\n",
              "      <td>-3.275579</td>\n",
              "      <td>-3.165511</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.800018</td>\n",
              "      <td>-3.350719</td>\n",
              "      <td>-3.716563</td>\n",
              "      <td>-3.786347</td>\n",
              "      <td>-2.966165</td>\n",
              "      <td>-3.581239</td>\n",
              "      <td>-3.027477</td>\n",
              "      <td>-3.198224</td>\n",
              "      <td>-3.178883</td>\n",
              "      <td>-3.403554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.733029</td>\n",
              "      <td>-0.766087</td>\n",
              "      <td>-0.754857</td>\n",
              "      <td>-0.757999</td>\n",
              "      <td>-0.733180</td>\n",
              "      <td>-0.782607</td>\n",
              "      <td>-0.739638</td>\n",
              "      <td>-0.765864</td>\n",
              "      <td>-0.780424</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.720434</td>\n",
              "      <td>-0.754353</td>\n",
              "      <td>-0.700030</td>\n",
              "      <td>-0.686601</td>\n",
              "      <td>-0.755173</td>\n",
              "      <td>-0.721236</td>\n",
              "      <td>-0.781139</td>\n",
              "      <td>-0.709355</td>\n",
              "      <td>-0.678068</td>\n",
              "      <td>-0.752610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.051714</td>\n",
              "      <td>0.007277</td>\n",
              "      <td>-0.051627</td>\n",
              "      <td>0.012661</td>\n",
              "      <td>0.019818</td>\n",
              "      <td>0.029068</td>\n",
              "      <td>-0.030693</td>\n",
              "      <td>-0.031333</td>\n",
              "      <td>0.034429</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005524</td>\n",
              "      <td>-0.031889</td>\n",
              "      <td>-0.017680</td>\n",
              "      <td>0.016314</td>\n",
              "      <td>-0.014715</td>\n",
              "      <td>-0.022745</td>\n",
              "      <td>0.016888</td>\n",
              "      <td>-0.019159</td>\n",
              "      <td>0.021814</td>\n",
              "      <td>0.048935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.682428</td>\n",
              "      <td>0.736870</td>\n",
              "      <td>0.682009</td>\n",
              "      <td>0.749271</td>\n",
              "      <td>0.730105</td>\n",
              "      <td>0.762410</td>\n",
              "      <td>0.683329</td>\n",
              "      <td>0.746614</td>\n",
              "      <td>0.797221</td>\n",
              "      <td>...</td>\n",
              "      <td>0.694945</td>\n",
              "      <td>0.682604</td>\n",
              "      <td>0.690644</td>\n",
              "      <td>0.719529</td>\n",
              "      <td>0.763197</td>\n",
              "      <td>0.679820</td>\n",
              "      <td>0.780439</td>\n",
              "      <td>0.744927</td>\n",
              "      <td>0.727881</td>\n",
              "      <td>0.782822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.169391</td>\n",
              "      <td>2.964030</td>\n",
              "      <td>3.270797</td>\n",
              "      <td>3.128139</td>\n",
              "      <td>3.445820</td>\n",
              "      <td>2.838130</td>\n",
              "      <td>3.506501</td>\n",
              "      <td>3.260893</td>\n",
              "      <td>2.960770</td>\n",
              "      <td>...</td>\n",
              "      <td>3.332820</td>\n",
              "      <td>3.010882</td>\n",
              "      <td>4.379381</td>\n",
              "      <td>3.744977</td>\n",
              "      <td>3.168908</td>\n",
              "      <td>3.088768</td>\n",
              "      <td>2.936766</td>\n",
              "      <td>3.355213</td>\n",
              "      <td>3.390432</td>\n",
              "      <td>3.049173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target              0              1              2  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean        0.099594      -0.001368       0.000998       0.000074   \n",
              "std         0.299459       1.000199       0.999324       0.999711   \n",
              "min         0.000000      -3.378739      -3.312510      -3.255758   \n",
              "25%         0.000000      -0.733029      -0.766087      -0.754857   \n",
              "50%         0.000000      -0.051714       0.007277      -0.051627   \n",
              "75%         0.000000       0.682428       0.736870       0.682009   \n",
              "max         1.000000       3.169391       2.964030       3.270797   \n",
              "\n",
              "                   3              4              5              6  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean       -0.001077       0.002315      -0.001045      -0.001867   \n",
              "std         1.001524       0.999005       1.000244       0.998705   \n",
              "min        -3.345903      -3.698703      -3.496937      -3.532923   \n",
              "25%        -0.757999      -0.733180      -0.782607      -0.739638   \n",
              "50%         0.012661       0.019818       0.029068      -0.030693   \n",
              "75%         0.749271       0.730105       0.762410       0.683329   \n",
              "max         3.128139       3.445820       2.838130       3.506501   \n",
              "\n",
              "                   7              8      ...                  190  \\\n",
              "count  160000.000000  160000.000000      ...        160000.000000   \n",
              "mean       -0.002470       0.000271      ...             0.000165   \n",
              "std         1.000824       1.000738      ...             0.999272   \n",
              "min        -3.275579      -3.165511      ...            -3.800018   \n",
              "25%        -0.765864      -0.780424      ...            -0.720434   \n",
              "50%        -0.031333       0.034429      ...            -0.005524   \n",
              "75%         0.746614       0.797221      ...             0.694945   \n",
              "max         3.260893       2.960770      ...             3.332820   \n",
              "\n",
              "                 191            192            193            194  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean       -0.001276       0.000912       0.000753      -0.002370   \n",
              "std         0.999214       0.999513       0.999254       0.999717   \n",
              "min        -3.350719      -3.716563      -3.786347      -2.966165   \n",
              "25%        -0.754353      -0.700030      -0.686601      -0.755173   \n",
              "50%        -0.031889      -0.017680       0.016314      -0.014715   \n",
              "75%         0.682604       0.690644       0.719529       0.763197   \n",
              "max         3.010882       4.379381       3.744977       3.168908   \n",
              "\n",
              "                 195            196            197            198  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean       -0.000563      -0.001272       0.001376      -0.000204   \n",
              "std         1.000286       1.000277       1.000812       1.000201   \n",
              "min        -3.581239      -3.027477      -3.198224      -3.178883   \n",
              "25%        -0.721236      -0.781139      -0.709355      -0.678068   \n",
              "50%        -0.022745       0.016888      -0.019159       0.021814   \n",
              "75%         0.679820       0.780439       0.744927       0.727881   \n",
              "max         3.088768       2.936766       3.355213       3.390432   \n",
              "\n",
              "                 199  \n",
              "count  160000.000000  \n",
              "mean        0.000563  \n",
              "std         0.999229  \n",
              "min        -3.403554  \n",
              "25%        -0.752610  \n",
              "50%         0.048935  \n",
              "75%         0.782822  \n",
              "max         3.049173  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "OjtBplKkB7Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1ab4d093-0bcf-45ec-fe1b-7c924a9e3789"
      },
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "test.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 201)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "ILxtyU7FCYE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train=train.iloc[:,1:]\n",
        "X_test=test.iloc[:,1:]\n",
        "y_train=train.iloc[:,0:1]\n",
        "y_test=test.iloc[:,0:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZIza5Z4AAXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d966ea9f-5c63-4a86-bb3b-872ce9dc54aa"
      },
      "cell_type": "code",
      "source": [
        "y_test.describe()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.301001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             target\n",
              "count  40000.000000\n",
              "mean       0.100750\n",
              "std        0.301001\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        0.000000\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "hWuLehhxEPoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "70cb23c1-7807-4381-c924-7001c0df4fb4"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "RFC = RandomForestClassifier()  \n",
        "             \n",
        "RFC.fit(X_train, y_train)  \n",
        "y_pred = RFC.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35945    48]\n",
            " [ 3947    60]]\n",
            "Accuracy score is 0.900125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WZ2cFvaLE4Nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fb460399-99cf-41ae-fc41-972cc5605074"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35822    54]\n",
            " [ 4050    74]]\n",
            "Accuracy score is 0.8974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0jyQbif_E78E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "5510f461-38d1-4652-975e-02fb93151291"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35449   544]\n",
            " [ 2903  1104]]\n",
            "Accuracy score is 0.913825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xkEPPp3PLF9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "73ba261f-e60d-46b2-927e-563edbb9a672"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35367   509]\n",
            " [ 3020  1104]]\n",
            "Accuracy score is 0.911775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-f7nHUjRLMdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDLN61vhFVI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "f6b19d78-a8cc-4a9b-df2f-e2c8b10f8f1a"
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35867     9]\n",
            " [ 4058    66]]\n",
            "Accuracy score is 0.898325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-0mzF7necvTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "4223b799-718c-43a3-e8a0-d3a40e934e2c"
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35989     4]\n",
            " [ 3942    65]]\n",
            "Accuracy score is 0.90135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2uaDvSc9Nl_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e368e954-f0e8-4993-d591-c658b4c23546"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test) \n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35334   542]\n",
            " [ 2986  1138]]\n",
            "Accuracy score is 0.9118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9XL2t1sbEg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "087cf070-1d77-491a-9913-d2a56ba3a7e5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test) \n",
        "predictions = lda.predict_proba(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, lda.predict(X_test))\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, lda.predict(X_test)))\n",
        "predictions = lda.predict_proba(X_test)\n",
        "\n",
        "print(roc_auc_score(y_test, predictions[:,1]))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, predictions[:,1])\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35333   504]\n",
            " [ 2997  1166]]\n",
            "Accuracy score is 0.912475\n",
            "0.633011399446922\n",
            "0.633011399446922\n",
            "0.8652957527534239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hjqThKEZQT5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35333   504]\n",
        " [ 2997  1166]]\n",
        "Accuracy score is 0.912475\n",
        "0.633011399446922\n",
        "0.633011399446922\n",
        "0.8652957527534239"
      ]
    },
    {
      "metadata": {
        "id": "4RpRq3DxQckn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "5cde2e0c-270d-474e-a672-70eff619c9cd"
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = model.predict_proba(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35832     5]\n",
            " [ 4090    73]]\n",
            "Accuracy score is 0.897625\n",
            "0.5086979552861222\n",
            "0.5086979552861222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8gd91MSxWqpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35832     5]\n",
        " [ 4090    73]]\n",
        "Accuracy score is 0.897625\n",
        "0.5086979552861222\n",
        "0.5086979552861222"
      ]
    },
    {
      "metadata": {
        "id": "s1kUdo5PWsqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "428c826e-9e02-4c4e-ee95-26a3e20d2e5e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = model.predict_proba(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35360   477]\n",
            " [ 3036  1127]]\n",
            "Accuracy score is 0.912175\n",
            "0.6287039830589609\n",
            "0.6287039830589609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Vhc8sPIW2TE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[[35360   477]\n",
        " [ 3036  1127]]\n",
        "Accuracy score is 0.912175\n",
        "0.6287039830589609\n",
        "0.6287039830589609"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nlv-Y2rAXGR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35360   477]\n",
        " [ 3036  1127]]\n",
        "Accuracy score is 0.912175\n",
        "0.6287039830589609\n",
        "0.6287039830589609"
      ]
    },
    {
      "metadata": {
        "id": "pxZWxGIPXL9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}