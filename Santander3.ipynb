{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santander3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogut77/LogisticRegression/blob/master/Santander3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5Oy-FBOFe7K1",
        "colab_type": "code",
        "outputId": "9959d271-8b5a-4a9d-cd08-e3b2cd8e117f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "   "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LUNC1WewPKlH",
        "colab_type": "code",
        "outputId": "0b74ab14-d05d-414f-b90a-b04c34951985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yhf-eYWiPnld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/content/.kaggle/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZNFh7SvFQwCN",
        "colab_type": "code",
        "outputId": "2813ebb5-72e7-4289-b232-e5d36f6caf4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/santander/'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv.zip  test.csv.zip  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L9oluC0eQW1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "token = {\"username\":\"hulisi\",\"key\":\"4163066d5cebf9ad2cc14e4ef9a71c3c\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSzSmL1DQgzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp '/content/.kaggle/kaggle.json' ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uDK6cUrvQnbp",
        "colab_type": "code",
        "outputId": "2bd75c2e-290b-443a-fe9f-5f1badf28577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle config set -n path -v{/content/}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content/}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FhGz7PSuRzi9",
        "colab_type": "code",
        "outputId": "26df649b-6b73-46cd-f256-d186cce3274b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c santander-customer-transaction-prediction -p /content/"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading train.csv.zip to /content\n",
            " 99% 121M/122M [00:02<00:00, 28.7MB/s]\n",
            "100% 122M/122M [00:02<00:00, 44.6MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/463k [00:00<?, ?B/s]\n",
            "100% 463k/463k [00:00<00:00, 106MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 98% 119M/122M [00:00<00:00, 144MB/s]\n",
            "100% 122M/122M [00:00<00:00, 141MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "05UOpdKESEml",
        "colab_type": "code",
        "outputId": "44b900d8-0cb9-4813-fe60-b6a36f9a54ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t     sample_submission.csv.zip\ttest.csv.zip\n",
            "sample_data  santander\t\t\ttrain.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UT7LM27dV0o4",
        "colab_type": "code",
        "outputId": "888acb57-8cc2-4a12-fb92-ab8c5794d349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "cell_type": "code",
      "source": [
        "d2 = pd.read_csv('/content/drive/My Drive/Santander/train.csv')\n",
        "d2.head()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>train_2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>train_4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 203 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
              "0           0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
              "1           1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
              "2           2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
              "3           3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
              "4           4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
              "\n",
              "    var_5   var_6   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
              "0 -9.2834  5.1187   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
              "1  7.0433  5.6208   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
              "2 -9.0837  6.9427   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
              "3 -1.8361  5.8428   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
              "4  2.4486  5.9405   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
              "\n",
              "   var_195  var_196  var_197  var_198  var_199  \n",
              "0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
              "2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 203 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "cziuHOHNCKH1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d2.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rb_xkC9A_J8O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d2.drop(['ID_code'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7O3VgxcDt9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "06ba065a-dcb8-46da-eb86-8e911a127ff9"
      },
      "cell_type": "code",
      "source": [
        "d2.head()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>-4.9200</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>3.1468</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>-4.9193</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>-5.8609</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>6.2654</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
              "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
              "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
              "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
              "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
              "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
              "\n",
              "    var_8   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
              "0 -4.9200   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
              "1  3.1468   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
              "2 -4.9193   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
              "3 -5.8609   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
              "4  6.2654   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
              "\n",
              "   var_196  var_197  var_198  var_199  \n",
              "0   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   8.1267   8.7889  18.3560   1.9518  \n",
              "2  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "metadata": {
        "id": "KChM4XPV_Hnf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sWuUSK95OoZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dx=d2.iloc[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVvhYw69SHmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dy=d2.iloc[:,0:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YY41XFFOthp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "ac00b04c-4df6-4a8e-ea86-7249aeed1286"
      },
      "cell_type": "code",
      "source": [
        "dx = pd.DataFrame(dx)\n",
        "dx.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>var_9</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>-4.9200</td>\n",
              "      <td>5.7470</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>3.1468</td>\n",
              "      <td>8.0851</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>-4.9193</td>\n",
              "      <td>5.9525</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>-5.8609</td>\n",
              "      <td>8.2450</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>6.2654</td>\n",
              "      <td>7.6784</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
              "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
              "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
              "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
              "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
              "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
              "\n",
              "    var_9   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
              "0  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
              "1  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
              "2  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
              "3  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
              "4  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
              "\n",
              "   var_196  var_197  var_198  var_199  \n",
              "0   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   8.1267   8.7889  18.3560   1.9518  \n",
              "2  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 200 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "metadata": {
        "id": "Q2-da6OJOWZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()  \n",
        "dx = sc.fit_transform(dx) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtrfQ3qgOmkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "5d2e7003-5eae-44a9-9fa9-7421d79f39de"
      },
      "cell_type": "code",
      "source": [
        "dx = pd.DataFrame(dx)\n",
        "dx.shape\n",
        "dx.head()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.529144</td>\n",
              "      <td>-1.321758</td>\n",
              "      <td>0.331936</td>\n",
              "      <td>0.076037</td>\n",
              "      <td>0.486149</td>\n",
              "      <td>0.986322</td>\n",
              "      <td>0.604114</td>\n",
              "      <td>-0.113983</td>\n",
              "      <td>0.300075</td>\n",
              "      <td>0.068793</td>\n",
              "      <td>...</td>\n",
              "      <td>0.083548</td>\n",
              "      <td>-1.600708</td>\n",
              "      <td>0.111059</td>\n",
              "      <td>-1.042115</td>\n",
              "      <td>0.194579</td>\n",
              "      <td>-1.750237</td>\n",
              "      <td>-0.228065</td>\n",
              "      <td>-0.362497</td>\n",
              "      <td>0.546830</td>\n",
              "      <td>-0.981711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.314702</td>\n",
              "      <td>-0.094768</td>\n",
              "      <td>0.597315</td>\n",
              "      <td>1.263057</td>\n",
              "      <td>0.106570</td>\n",
              "      <td>-1.259286</td>\n",
              "      <td>-1.378099</td>\n",
              "      <td>0.131403</td>\n",
              "      <td>-1.170218</td>\n",
              "      <td>-0.672782</td>\n",
              "      <td>...</td>\n",
              "      <td>1.181679</td>\n",
              "      <td>-0.612212</td>\n",
              "      <td>-0.845026</td>\n",
              "      <td>-0.567252</td>\n",
              "      <td>0.009273</td>\n",
              "      <td>-1.354643</td>\n",
              "      <td>1.360647</td>\n",
              "      <td>-0.131858</td>\n",
              "      <td>0.100923</td>\n",
              "      <td>-0.259530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.047399</td>\n",
              "      <td>-1.543014</td>\n",
              "      <td>0.533194</td>\n",
              "      <td>-0.327538</td>\n",
              "      <td>-0.173090</td>\n",
              "      <td>0.350186</td>\n",
              "      <td>0.801021</td>\n",
              "      <td>-0.058825</td>\n",
              "      <td>-1.404957</td>\n",
              "      <td>2.290167</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038384</td>\n",
              "      <td>0.686378</td>\n",
              "      <td>0.391925</td>\n",
              "      <td>-0.009180</td>\n",
              "      <td>0.058755</td>\n",
              "      <td>-0.208516</td>\n",
              "      <td>-0.699995</td>\n",
              "      <td>1.719948</td>\n",
              "      <td>0.691847</td>\n",
              "      <td>-0.307908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.189880</td>\n",
              "      <td>0.602456</td>\n",
              "      <td>-0.771092</td>\n",
              "      <td>1.488016</td>\n",
              "      <td>-0.410913</td>\n",
              "      <td>0.092598</td>\n",
              "      <td>0.494689</td>\n",
              "      <td>0.101114</td>\n",
              "      <td>-1.005328</td>\n",
              "      <td>0.713937</td>\n",
              "      <td>...</td>\n",
              "      <td>1.622116</td>\n",
              "      <td>1.794875</td>\n",
              "      <td>0.705301</td>\n",
              "      <td>0.494924</td>\n",
              "      <td>0.268217</td>\n",
              "      <td>-0.841420</td>\n",
              "      <td>1.050389</td>\n",
              "      <td>-0.135779</td>\n",
              "      <td>0.336008</td>\n",
              "      <td>-1.680223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.554619</td>\n",
              "      <td>0.183962</td>\n",
              "      <td>-1.264786</td>\n",
              "      <td>-0.230476</td>\n",
              "      <td>-0.053585</td>\n",
              "      <td>-1.156959</td>\n",
              "      <td>-0.019276</td>\n",
              "      <td>-1.028456</td>\n",
              "      <td>1.599331</td>\n",
              "      <td>-0.005554</td>\n",
              "      <td>...</td>\n",
              "      <td>1.086851</td>\n",
              "      <td>-1.445677</td>\n",
              "      <td>0.382634</td>\n",
              "      <td>-0.184068</td>\n",
              "      <td>-1.206265</td>\n",
              "      <td>0.626516</td>\n",
              "      <td>-0.246147</td>\n",
              "      <td>-0.738633</td>\n",
              "      <td>0.287940</td>\n",
              "      <td>2.448163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.529144 -1.321758  0.331936  0.076037  0.486149  0.986322  0.604114   \n",
              "1  2.314702 -0.094768  0.597315  1.263057  0.106570 -1.259286 -1.378099   \n",
              "2  0.047399 -1.543014  0.533194 -0.327538 -0.173090  0.350186  0.801021   \n",
              "3  1.189880  0.602456 -0.771092  1.488016 -0.410913  0.092598  0.494689   \n",
              "4  0.554619  0.183962 -1.264786 -0.230476 -0.053585 -1.156959 -0.019276   \n",
              "\n",
              "        7         8         9      ...          140       141       142  \\\n",
              "0 -0.113983  0.300075  0.068793    ...     0.083548 -1.600708  0.111059   \n",
              "1  0.131403 -1.170218 -0.672782    ...     1.181679 -0.612212 -0.845026   \n",
              "2 -0.058825 -1.404957  2.290167    ...    -0.038384  0.686378  0.391925   \n",
              "3  0.101114 -1.005328  0.713937    ...     1.622116  1.794875  0.705301   \n",
              "4 -1.028456  1.599331 -0.005554    ...     1.086851 -1.445677  0.382634   \n",
              "\n",
              "        143       144       145       146       147       148       149  \n",
              "0 -1.042115  0.194579 -1.750237 -0.228065 -0.362497  0.546830 -0.981711  \n",
              "1 -0.567252  0.009273 -1.354643  1.360647 -0.131858  0.100923 -0.259530  \n",
              "2 -0.009180  0.058755 -0.208516 -0.699995  1.719948  0.691847 -0.307908  \n",
              "3  0.494924  0.268217 -0.841420  1.050389 -0.135779  0.336008 -1.680223  \n",
              "4 -0.184068 -1.206265  0.626516 -0.246147 -0.738633  0.287940  2.448163  \n",
              "\n",
              "[5 rows x 150 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "Ws3tDBTdJRHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "da6dceb6-e947-4182-8f45-0fb83094fcaa"
      },
      "cell_type": "code",
      "source": [
        "dx.describe()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "      <td>2.000000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.264278e-17</td>\n",
              "      <td>-5.508927e-17</td>\n",
              "      <td>1.326324e-17</td>\n",
              "      <td>-2.429723e-17</td>\n",
              "      <td>-8.046896e-18</td>\n",
              "      <td>-7.552292e-18</td>\n",
              "      <td>-3.663458e-17</td>\n",
              "      <td>-3.237743e-17</td>\n",
              "      <td>-1.852185e-17</td>\n",
              "      <td>-4.054534e-17</td>\n",
              "      <td>...</td>\n",
              "      <td>1.392775e-17</td>\n",
              "      <td>2.286782e-17</td>\n",
              "      <td>-5.823120e-18</td>\n",
              "      <td>3.290118e-17</td>\n",
              "      <td>2.576554e-17</td>\n",
              "      <td>5.896894e-17</td>\n",
              "      <td>5.128439e-17</td>\n",
              "      <td>1.405709e-17</td>\n",
              "      <td>4.406031e-17</td>\n",
              "      <td>2.398137e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.101493e+00</td>\n",
              "      <td>1.027496e+00</td>\n",
              "      <td>1.026879e+00</td>\n",
              "      <td>1.026419e+00</td>\n",
              "      <td>1.026193e+00</td>\n",
              "      <td>1.025398e+00</td>\n",
              "      <td>1.024444e+00</td>\n",
              "      <td>1.023834e+00</td>\n",
              "      <td>1.023558e+00</td>\n",
              "      <td>1.023296e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>9.825309e-01</td>\n",
              "      <td>9.822446e-01</td>\n",
              "      <td>9.818502e-01</td>\n",
              "      <td>9.813593e-01</td>\n",
              "      <td>9.806733e-01</td>\n",
              "      <td>9.805768e-01</td>\n",
              "      <td>9.804181e-01</td>\n",
              "      <td>9.800299e-01</td>\n",
              "      <td>9.798573e-01</td>\n",
              "      <td>9.792997e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.683073e+00</td>\n",
              "      <td>-4.370615e+00</td>\n",
              "      <td>-4.398201e+00</td>\n",
              "      <td>-4.500944e+00</td>\n",
              "      <td>-4.335169e+00</td>\n",
              "      <td>-4.252212e+00</td>\n",
              "      <td>-4.467492e+00</td>\n",
              "      <td>-4.442514e+00</td>\n",
              "      <td>-4.683042e+00</td>\n",
              "      <td>-4.215258e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.103992e+00</td>\n",
              "      <td>-4.187268e+00</td>\n",
              "      <td>-4.702061e+00</td>\n",
              "      <td>-4.591094e+00</td>\n",
              "      <td>-4.190143e+00</td>\n",
              "      <td>-4.239434e+00</td>\n",
              "      <td>-4.226821e+00</td>\n",
              "      <td>-4.270482e+00</td>\n",
              "      <td>-4.365201e+00</td>\n",
              "      <td>-4.547678e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.489999e-01</td>\n",
              "      <td>-6.937100e-01</td>\n",
              "      <td>-6.939401e-01</td>\n",
              "      <td>-6.920381e-01</td>\n",
              "      <td>-6.940512e-01</td>\n",
              "      <td>-6.914661e-01</td>\n",
              "      <td>-6.906722e-01</td>\n",
              "      <td>-6.924129e-01</td>\n",
              "      <td>-6.902483e-01</td>\n",
              "      <td>-6.922952e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.639196e-01</td>\n",
              "      <td>-6.618830e-01</td>\n",
              "      <td>-6.613212e-01</td>\n",
              "      <td>-6.633255e-01</td>\n",
              "      <td>-6.618081e-01</td>\n",
              "      <td>-6.618037e-01</td>\n",
              "      <td>-6.624127e-01</td>\n",
              "      <td>-6.621547e-01</td>\n",
              "      <td>-6.618566e-01</td>\n",
              "      <td>-6.584941e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.936950e-02</td>\n",
              "      <td>-3.969168e-04</td>\n",
              "      <td>1.755160e-03</td>\n",
              "      <td>-3.024970e-04</td>\n",
              "      <td>2.032858e-03</td>\n",
              "      <td>-2.909175e-03</td>\n",
              "      <td>-8.183166e-04</td>\n",
              "      <td>3.971031e-04</td>\n",
              "      <td>2.125918e-03</td>\n",
              "      <td>1.748285e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>3.014346e-04</td>\n",
              "      <td>-3.052135e-03</td>\n",
              "      <td>-2.647545e-03</td>\n",
              "      <td>-1.746989e-03</td>\n",
              "      <td>-3.303214e-03</td>\n",
              "      <td>-4.235263e-04</td>\n",
              "      <td>-2.902051e-03</td>\n",
              "      <td>-1.491405e-03</td>\n",
              "      <td>1.722111e-03</td>\n",
              "      <td>1.776928e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.020343e-01</td>\n",
              "      <td>6.930307e-01</td>\n",
              "      <td>6.938623e-01</td>\n",
              "      <td>6.933638e-01</td>\n",
              "      <td>6.906039e-01</td>\n",
              "      <td>6.925068e-01</td>\n",
              "      <td>6.897978e-01</td>\n",
              "      <td>6.893202e-01</td>\n",
              "      <td>6.895185e-01</td>\n",
              "      <td>6.910309e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>6.623036e-01</td>\n",
              "      <td>6.634971e-01</td>\n",
              "      <td>6.605371e-01</td>\n",
              "      <td>6.634623e-01</td>\n",
              "      <td>6.615050e-01</td>\n",
              "      <td>6.624758e-01</td>\n",
              "      <td>6.629554e-01</td>\n",
              "      <td>6.597647e-01</td>\n",
              "      <td>6.631402e-01</td>\n",
              "      <td>6.629438e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.938376e+00</td>\n",
              "      <td>4.819486e+00</td>\n",
              "      <td>4.488833e+00</td>\n",
              "      <td>4.585744e+00</td>\n",
              "      <td>6.166446e+00</td>\n",
              "      <td>4.567724e+00</td>\n",
              "      <td>4.488799e+00</td>\n",
              "      <td>4.873452e+00</td>\n",
              "      <td>4.729443e+00</td>\n",
              "      <td>4.937578e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>5.431009e+00</td>\n",
              "      <td>4.871860e+00</td>\n",
              "      <td>4.717397e+00</td>\n",
              "      <td>4.990465e+00</td>\n",
              "      <td>4.251100e+00</td>\n",
              "      <td>4.410511e+00</td>\n",
              "      <td>4.289014e+00</td>\n",
              "      <td>4.271594e+00</td>\n",
              "      <td>5.168137e+00</td>\n",
              "      <td>4.966518e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0             1             2             3             4    \\\n",
              "count  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
              "mean   3.264278e-17 -5.508927e-17  1.326324e-17 -2.429723e-17 -8.046896e-18   \n",
              "std    1.101493e+00  1.027496e+00  1.026879e+00  1.026419e+00  1.026193e+00   \n",
              "min   -4.683073e+00 -4.370615e+00 -4.398201e+00 -4.500944e+00 -4.335169e+00   \n",
              "25%   -7.489999e-01 -6.937100e-01 -6.939401e-01 -6.920381e-01 -6.940512e-01   \n",
              "50%   -3.936950e-02 -3.969168e-04  1.755160e-03 -3.024970e-04  2.032858e-03   \n",
              "75%    7.020343e-01  6.930307e-01  6.938623e-01  6.933638e-01  6.906039e-01   \n",
              "max    5.938376e+00  4.819486e+00  4.488833e+00  4.585744e+00  6.166446e+00   \n",
              "\n",
              "                5             6             7             8             9    \\\n",
              "count  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
              "mean  -7.552292e-18 -3.663458e-17 -3.237743e-17 -1.852185e-17 -4.054534e-17   \n",
              "std    1.025398e+00  1.024444e+00  1.023834e+00  1.023558e+00  1.023296e+00   \n",
              "min   -4.252212e+00 -4.467492e+00 -4.442514e+00 -4.683042e+00 -4.215258e+00   \n",
              "25%   -6.914661e-01 -6.906722e-01 -6.924129e-01 -6.902483e-01 -6.922952e-01   \n",
              "50%   -2.909175e-03 -8.183166e-04  3.971031e-04  2.125918e-03  1.748285e-03   \n",
              "75%    6.925068e-01  6.897978e-01  6.893202e-01  6.895185e-01  6.910309e-01   \n",
              "max    4.567724e+00  4.488799e+00  4.873452e+00  4.729443e+00  4.937578e+00   \n",
              "\n",
              "           ...                140           141           142           143  \\\n",
              "count      ...       2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
              "mean       ...       1.392775e-17  2.286782e-17 -5.823120e-18  3.290118e-17   \n",
              "std        ...       9.825309e-01  9.822446e-01  9.818502e-01  9.813593e-01   \n",
              "min        ...      -4.103992e+00 -4.187268e+00 -4.702061e+00 -4.591094e+00   \n",
              "25%        ...      -6.639196e-01 -6.618830e-01 -6.613212e-01 -6.633255e-01   \n",
              "50%        ...       3.014346e-04 -3.052135e-03 -2.647545e-03 -1.746989e-03   \n",
              "75%        ...       6.623036e-01  6.634971e-01  6.605371e-01  6.634623e-01   \n",
              "max        ...       5.431009e+00  4.871860e+00  4.717397e+00  4.990465e+00   \n",
              "\n",
              "                144           145           146           147           148  \\\n",
              "count  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
              "mean   2.576554e-17  5.896894e-17  5.128439e-17  1.405709e-17  4.406031e-17   \n",
              "std    9.806733e-01  9.805768e-01  9.804181e-01  9.800299e-01  9.798573e-01   \n",
              "min   -4.190143e+00 -4.239434e+00 -4.226821e+00 -4.270482e+00 -4.365201e+00   \n",
              "25%   -6.618081e-01 -6.618037e-01 -6.624127e-01 -6.621547e-01 -6.618566e-01   \n",
              "50%   -3.303214e-03 -4.235263e-04 -2.902051e-03 -1.491405e-03  1.722111e-03   \n",
              "75%    6.615050e-01  6.624758e-01  6.629554e-01  6.597647e-01  6.631402e-01   \n",
              "max    4.251100e+00  4.410511e+00  4.289014e+00  4.271594e+00  5.168137e+00   \n",
              "\n",
              "                149  \n",
              "count  2.000000e+05  \n",
              "mean   2.398137e-17  \n",
              "std    9.792997e-01  \n",
              "min   -4.547678e+00  \n",
              "25%   -6.584941e-01  \n",
              "50%    1.776928e-03  \n",
              "75%    6.629438e-01  \n",
              "max    4.966518e+00  \n",
              "\n",
              "[8 rows x 150 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "lBpR2xqBR_Y6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#merge dx with dy if scale \n",
        "\n",
        "dt=pd.concat([dy, dx], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WAyHXXUaUc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "f2ea2ced-1b5a-4b85-a824-a7b20b88e29a"
      },
      "cell_type": "code",
      "source": [
        "dt.head(2)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.529144</td>\n",
              "      <td>-1.321758</td>\n",
              "      <td>0.331936</td>\n",
              "      <td>0.076037</td>\n",
              "      <td>0.486149</td>\n",
              "      <td>0.986322</td>\n",
              "      <td>0.604114</td>\n",
              "      <td>-0.113983</td>\n",
              "      <td>0.300075</td>\n",
              "      <td>...</td>\n",
              "      <td>0.083548</td>\n",
              "      <td>-1.600708</td>\n",
              "      <td>0.111059</td>\n",
              "      <td>-1.042115</td>\n",
              "      <td>0.194579</td>\n",
              "      <td>-1.750237</td>\n",
              "      <td>-0.228065</td>\n",
              "      <td>-0.362497</td>\n",
              "      <td>0.546830</td>\n",
              "      <td>-0.981711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2.314702</td>\n",
              "      <td>-0.094768</td>\n",
              "      <td>0.597315</td>\n",
              "      <td>1.263057</td>\n",
              "      <td>0.106570</td>\n",
              "      <td>-1.259286</td>\n",
              "      <td>-1.378099</td>\n",
              "      <td>0.131403</td>\n",
              "      <td>-1.170218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.181679</td>\n",
              "      <td>-0.612212</td>\n",
              "      <td>-0.845026</td>\n",
              "      <td>-0.567252</td>\n",
              "      <td>0.009273</td>\n",
              "      <td>-1.354643</td>\n",
              "      <td>1.360647</td>\n",
              "      <td>-0.131858</td>\n",
              "      <td>0.100923</td>\n",
              "      <td>-0.259530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 151 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         0         1         2         3         4         5  \\\n",
              "0       0 -0.529144 -1.321758  0.331936  0.076037  0.486149  0.986322   \n",
              "1       0  2.314702 -0.094768  0.597315  1.263057  0.106570 -1.259286   \n",
              "\n",
              "          6         7         8    ...          140       141       142  \\\n",
              "0  0.604114 -0.113983  0.300075    ...     0.083548 -1.600708  0.111059   \n",
              "1 -1.378099  0.131403 -1.170218    ...     1.181679 -0.612212 -0.845026   \n",
              "\n",
              "        143       144       145       146       147       148       149  \n",
              "0 -1.042115  0.194579 -1.750237 -0.228065 -0.362497  0.546830 -0.981711  \n",
              "1 -0.567252  0.009273 -1.354643  1.360647 -0.131858  0.100923 -0.259530  \n",
              "\n",
              "[2 rows x 151 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "0I6JrfxaWEat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dt, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvT1-3aYOUUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "b48b79ad-1fd7-4969-e11c-ea870353feed"
      },
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100388</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000915</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.000719</td>\n",
              "      <td>0.001928</td>\n",
              "      <td>0.002439</td>\n",
              "      <td>-0.000157</td>\n",
              "      <td>0.001634</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000814</td>\n",
              "      <td>-0.000191</td>\n",
              "      <td>-0.000834</td>\n",
              "      <td>-0.000099</td>\n",
              "      <td>-0.000090</td>\n",
              "      <td>-0.000208</td>\n",
              "      <td>-0.001015</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>-0.000832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.300517</td>\n",
              "      <td>1.098849</td>\n",
              "      <td>1.027368</td>\n",
              "      <td>1.025951</td>\n",
              "      <td>1.027237</td>\n",
              "      <td>1.027026</td>\n",
              "      <td>1.025883</td>\n",
              "      <td>1.024131</td>\n",
              "      <td>1.023585</td>\n",
              "      <td>1.023739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.982454</td>\n",
              "      <td>0.983224</td>\n",
              "      <td>0.982086</td>\n",
              "      <td>0.981465</td>\n",
              "      <td>0.980780</td>\n",
              "      <td>0.981010</td>\n",
              "      <td>0.981055</td>\n",
              "      <td>0.979325</td>\n",
              "      <td>0.980505</td>\n",
              "      <td>0.979388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.343509</td>\n",
              "      <td>-4.370615</td>\n",
              "      <td>-4.358870</td>\n",
              "      <td>-4.500944</td>\n",
              "      <td>-4.335169</td>\n",
              "      <td>-4.083969</td>\n",
              "      <td>-4.369663</td>\n",
              "      <td>-4.442514</td>\n",
              "      <td>-4.683042</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.103992</td>\n",
              "      <td>-4.187268</td>\n",
              "      <td>-4.702061</td>\n",
              "      <td>-4.181393</td>\n",
              "      <td>-4.190143</td>\n",
              "      <td>-4.239434</td>\n",
              "      <td>-4.226821</td>\n",
              "      <td>-4.270482</td>\n",
              "      <td>-4.365201</td>\n",
              "      <td>-4.547678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.747033</td>\n",
              "      <td>-0.694194</td>\n",
              "      <td>-0.690232</td>\n",
              "      <td>-0.689406</td>\n",
              "      <td>-0.694120</td>\n",
              "      <td>-0.688119</td>\n",
              "      <td>-0.686038</td>\n",
              "      <td>-0.693471</td>\n",
              "      <td>-0.688825</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.665525</td>\n",
              "      <td>-0.663582</td>\n",
              "      <td>-0.662257</td>\n",
              "      <td>-0.663117</td>\n",
              "      <td>-0.661910</td>\n",
              "      <td>-0.661606</td>\n",
              "      <td>-0.662722</td>\n",
              "      <td>-0.660989</td>\n",
              "      <td>-0.661804</td>\n",
              "      <td>-0.658554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.036403</td>\n",
              "      <td>-0.001356</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>0.002335</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.001891</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.003665</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000175</td>\n",
              "      <td>-0.004319</td>\n",
              "      <td>-0.003457</td>\n",
              "      <td>-0.001323</td>\n",
              "      <td>-0.003468</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>-0.003104</td>\n",
              "      <td>-0.001591</td>\n",
              "      <td>0.002405</td>\n",
              "      <td>0.000486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704788</td>\n",
              "      <td>0.693595</td>\n",
              "      <td>0.694576</td>\n",
              "      <td>0.694821</td>\n",
              "      <td>0.691018</td>\n",
              "      <td>0.695197</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.689741</td>\n",
              "      <td>0.691011</td>\n",
              "      <td>...</td>\n",
              "      <td>0.659255</td>\n",
              "      <td>0.665139</td>\n",
              "      <td>0.661263</td>\n",
              "      <td>0.663886</td>\n",
              "      <td>0.662483</td>\n",
              "      <td>0.661970</td>\n",
              "      <td>0.661004</td>\n",
              "      <td>0.659765</td>\n",
              "      <td>0.664705</td>\n",
              "      <td>0.661572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.707648</td>\n",
              "      <td>4.254368</td>\n",
              "      <td>4.488833</td>\n",
              "      <td>4.585744</td>\n",
              "      <td>6.166446</td>\n",
              "      <td>4.567724</td>\n",
              "      <td>4.488799</td>\n",
              "      <td>4.873452</td>\n",
              "      <td>4.729443</td>\n",
              "      <td>...</td>\n",
              "      <td>5.431009</td>\n",
              "      <td>4.871860</td>\n",
              "      <td>4.717397</td>\n",
              "      <td>4.990465</td>\n",
              "      <td>4.251100</td>\n",
              "      <td>4.410511</td>\n",
              "      <td>4.289014</td>\n",
              "      <td>4.271594</td>\n",
              "      <td>5.168137</td>\n",
              "      <td>4.966518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 151 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target              0              1              2  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean        0.100388       0.002492       0.000215       0.000915   \n",
              "std         0.300517       1.098849       1.027368       1.025951   \n",
              "min         0.000000      -4.343509      -4.370615      -4.358870   \n",
              "25%         0.000000      -0.747033      -0.694194      -0.690232   \n",
              "50%         0.000000      -0.036403      -0.001356       0.002104   \n",
              "75%         0.000000       0.704788       0.693595       0.694576   \n",
              "max         1.000000       5.707648       4.254368       4.488833   \n",
              "\n",
              "                   3              4              5              6  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean        0.001937       0.000719       0.001928       0.002439   \n",
              "std         1.027237       1.027026       1.025883       1.024131   \n",
              "min        -4.500944      -4.335169      -4.083969      -4.369663   \n",
              "25%        -0.689406      -0.694120      -0.688119      -0.686038   \n",
              "50%         0.002335       0.003219       0.000171       0.001891   \n",
              "75%         0.694821       0.691018       0.695197       0.693147   \n",
              "max         4.585744       6.166446       4.567724       4.488799   \n",
              "\n",
              "                   7              8      ...                  140  \\\n",
              "count  160000.000000  160000.000000      ...        160000.000000   \n",
              "mean       -0.000157       0.001634      ...            -0.000814   \n",
              "std         1.023585       1.023739      ...             0.982454   \n",
              "min        -4.442514      -4.683042      ...            -4.103992   \n",
              "25%        -0.693471      -0.688825      ...            -0.665525   \n",
              "50%         0.000155       0.003665      ...            -0.000175   \n",
              "75%         0.689741       0.691011      ...             0.659255   \n",
              "max         4.873452       4.729443      ...             5.431009   \n",
              "\n",
              "                 141            142            143            144  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean       -0.000191      -0.000834      -0.000099      -0.000090   \n",
              "std         0.983224       0.982086       0.981465       0.980780   \n",
              "min        -4.187268      -4.702061      -4.181393      -4.190143   \n",
              "25%        -0.663582      -0.662257      -0.663117      -0.661910   \n",
              "50%        -0.004319      -0.003457      -0.001323      -0.003468   \n",
              "75%         0.665139       0.661263       0.663886       0.662483   \n",
              "max         4.871860       4.717397       4.990465       4.251100   \n",
              "\n",
              "                 145            146            147            148  \\\n",
              "count  160000.000000  160000.000000  160000.000000  160000.000000   \n",
              "mean       -0.000208      -0.001015       0.000917       0.000576   \n",
              "std         0.981010       0.981055       0.979325       0.980505   \n",
              "min        -4.239434      -4.226821      -4.270482      -4.365201   \n",
              "25%        -0.661606      -0.662722      -0.660989      -0.661804   \n",
              "50%         0.000082      -0.003104      -0.001591       0.002405   \n",
              "75%         0.661970       0.661004       0.659765       0.664705   \n",
              "max         4.410511       4.289014       4.271594       5.168137   \n",
              "\n",
              "                 149  \n",
              "count  160000.000000  \n",
              "mean       -0.000832  \n",
              "std         0.979388  \n",
              "min        -4.547678  \n",
              "25%        -0.658554  \n",
              "50%         0.000486  \n",
              "75%         0.661572  \n",
              "max         4.966518  \n",
              "\n",
              "[8 rows x 151 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "metadata": {
        "id": "OjtBplKkB7Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f2980cf5-6c5a-49c3-8212-2ab7b49aa992"
      },
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "test.shape"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 151)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 151)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "metadata": {
        "id": "xgsHaHHj-4PI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "73f4908a-48c1-4665-e2fc-328defd48cc5"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39846</th>\n",
              "      <td>0</td>\n",
              "      <td>0.895911</td>\n",
              "      <td>-1.269637</td>\n",
              "      <td>1.595172</td>\n",
              "      <td>-1.122883</td>\n",
              "      <td>1.769802</td>\n",
              "      <td>-1.734320</td>\n",
              "      <td>-0.152944</td>\n",
              "      <td>-1.437989</td>\n",
              "      <td>-1.456765</td>\n",
              "      <td>...</td>\n",
              "      <td>2.017390</td>\n",
              "      <td>-0.661444</td>\n",
              "      <td>-0.140218</td>\n",
              "      <td>-0.920221</td>\n",
              "      <td>-1.191208</td>\n",
              "      <td>1.895771</td>\n",
              "      <td>-0.122796</td>\n",
              "      <td>-0.409913</td>\n",
              "      <td>1.258262</td>\n",
              "      <td>1.654723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92623</th>\n",
              "      <td>0</td>\n",
              "      <td>0.081698</td>\n",
              "      <td>0.874491</td>\n",
              "      <td>1.148380</td>\n",
              "      <td>0.612312</td>\n",
              "      <td>1.308467</td>\n",
              "      <td>-0.961393</td>\n",
              "      <td>1.829876</td>\n",
              "      <td>1.515396</td>\n",
              "      <td>1.408539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010329</td>\n",
              "      <td>1.865223</td>\n",
              "      <td>-0.063733</td>\n",
              "      <td>1.276376</td>\n",
              "      <td>-1.105407</td>\n",
              "      <td>-0.432226</td>\n",
              "      <td>0.767482</td>\n",
              "      <td>-2.316392</td>\n",
              "      <td>-1.432714</td>\n",
              "      <td>0.160592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21222</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.824188</td>\n",
              "      <td>-0.799838</td>\n",
              "      <td>0.552824</td>\n",
              "      <td>2.025502</td>\n",
              "      <td>-0.581667</td>\n",
              "      <td>1.984731</td>\n",
              "      <td>-0.365197</td>\n",
              "      <td>0.091290</td>\n",
              "      <td>-0.106883</td>\n",
              "      <td>...</td>\n",
              "      <td>0.884960</td>\n",
              "      <td>1.244404</td>\n",
              "      <td>1.367107</td>\n",
              "      <td>0.473790</td>\n",
              "      <td>1.403777</td>\n",
              "      <td>-0.230374</td>\n",
              "      <td>1.187457</td>\n",
              "      <td>0.987276</td>\n",
              "      <td>-1.838769</td>\n",
              "      <td>-1.719960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179748</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.493687</td>\n",
              "      <td>-0.263326</td>\n",
              "      <td>-1.276952</td>\n",
              "      <td>0.076836</td>\n",
              "      <td>0.349561</td>\n",
              "      <td>0.875967</td>\n",
              "      <td>-0.440738</td>\n",
              "      <td>-0.262466</td>\n",
              "      <td>-1.270441</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.168887</td>\n",
              "      <td>-1.408755</td>\n",
              "      <td>-1.400412</td>\n",
              "      <td>-1.344836</td>\n",
              "      <td>-1.768302</td>\n",
              "      <td>0.714203</td>\n",
              "      <td>0.485513</td>\n",
              "      <td>1.186778</td>\n",
              "      <td>-0.528214</td>\n",
              "      <td>0.139086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150051</th>\n",
              "      <td>0</td>\n",
              "      <td>0.145983</td>\n",
              "      <td>-0.559017</td>\n",
              "      <td>1.621252</td>\n",
              "      <td>-1.564150</td>\n",
              "      <td>-0.435437</td>\n",
              "      <td>0.862154</td>\n",
              "      <td>1.107377</td>\n",
              "      <td>0.110321</td>\n",
              "      <td>-0.349958</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.390180</td>\n",
              "      <td>-0.156766</td>\n",
              "      <td>0.322884</td>\n",
              "      <td>-0.334683</td>\n",
              "      <td>-0.379085</td>\n",
              "      <td>-0.639884</td>\n",
              "      <td>0.097211</td>\n",
              "      <td>0.978555</td>\n",
              "      <td>-0.600003</td>\n",
              "      <td>0.645232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 151 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        target         0         1         2         3         4         5  \\\n",
              "39846        0  0.895911 -1.269637  1.595172 -1.122883  1.769802 -1.734320   \n",
              "92623        0  0.081698  0.874491  1.148380  0.612312  1.308467 -0.961393   \n",
              "21222        0 -0.824188 -0.799838  0.552824  2.025502 -0.581667  1.984731   \n",
              "179748       0 -0.493687 -0.263326 -1.276952  0.076836  0.349561  0.875967   \n",
              "150051       0  0.145983 -0.559017  1.621252 -1.564150 -0.435437  0.862154   \n",
              "\n",
              "               6         7         8    ...          140       141       142  \\\n",
              "39846  -0.152944 -1.437989 -1.456765    ...     2.017390 -0.661444 -0.140218   \n",
              "92623   1.829876  1.515396  1.408539    ...     0.010329  1.865223 -0.063733   \n",
              "21222  -0.365197  0.091290 -0.106883    ...     0.884960  1.244404  1.367107   \n",
              "179748 -0.440738 -0.262466 -1.270441    ...    -1.168887 -1.408755 -1.400412   \n",
              "150051  1.107377  0.110321 -0.349958    ...    -0.390180 -0.156766  0.322884   \n",
              "\n",
              "             143       144       145       146       147       148       149  \n",
              "39846  -0.920221 -1.191208  1.895771 -0.122796 -0.409913  1.258262  1.654723  \n",
              "92623   1.276376 -1.105407 -0.432226  0.767482 -2.316392 -1.432714  0.160592  \n",
              "21222   0.473790  1.403777 -0.230374  1.187457  0.987276 -1.838769 -1.719960  \n",
              "179748 -1.344836 -1.768302  0.714203  0.485513  1.186778 -0.528214  0.139086  \n",
              "150051 -0.334683 -0.379085 -0.639884  0.097211  0.978555 -0.600003  0.645232  \n",
              "\n",
              "[5 rows x 151 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "ILxtyU7FCYE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train=train.iloc[:,1:]\n",
        "X_test=test.iloc[:,1:]\n",
        "y_train=train.iloc[:,0:1]\n",
        "y_test=test.iloc[:,0:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZIza5Z4AAXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "8aaaa4a8-aa56-45ba-927d-16d6808717d3"
      },
      "cell_type": "code",
      "source": [
        "X_test.describe()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.009969</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>-0.003661</td>\n",
              "      <td>-0.007749</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>-0.007710</td>\n",
              "      <td>-0.009757</td>\n",
              "      <td>0.000628</td>\n",
              "      <td>-0.006537</td>\n",
              "      <td>-0.003391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003258</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>0.003336</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.000359</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>-0.003667</td>\n",
              "      <td>-0.002305</td>\n",
              "      <td>0.003330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.111967</td>\n",
              "      <td>1.028025</td>\n",
              "      <td>1.030586</td>\n",
              "      <td>1.023116</td>\n",
              "      <td>1.022865</td>\n",
              "      <td>1.023433</td>\n",
              "      <td>1.025653</td>\n",
              "      <td>1.024842</td>\n",
              "      <td>1.022819</td>\n",
              "      <td>1.024262</td>\n",
              "      <td>...</td>\n",
              "      <td>0.982844</td>\n",
              "      <td>0.978328</td>\n",
              "      <td>0.980911</td>\n",
              "      <td>0.980949</td>\n",
              "      <td>0.980259</td>\n",
              "      <td>0.978852</td>\n",
              "      <td>0.977869</td>\n",
              "      <td>0.982850</td>\n",
              "      <td>0.977271</td>\n",
              "      <td>0.978953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.683073</td>\n",
              "      <td>-4.085822</td>\n",
              "      <td>-4.398201</td>\n",
              "      <td>-4.227556</td>\n",
              "      <td>-4.171722</td>\n",
              "      <td>-4.252212</td>\n",
              "      <td>-4.467492</td>\n",
              "      <td>-4.323473</td>\n",
              "      <td>-4.375755</td>\n",
              "      <td>-4.035621</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.837154</td>\n",
              "      <td>-4.022554</td>\n",
              "      <td>-4.210793</td>\n",
              "      <td>-4.591094</td>\n",
              "      <td>-4.109285</td>\n",
              "      <td>-3.798605</td>\n",
              "      <td>-3.923197</td>\n",
              "      <td>-4.015625</td>\n",
              "      <td>-4.160880</td>\n",
              "      <td>-3.855955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.756994</td>\n",
              "      <td>-0.691476</td>\n",
              "      <td>-0.707846</td>\n",
              "      <td>-0.703444</td>\n",
              "      <td>-0.693633</td>\n",
              "      <td>-0.704269</td>\n",
              "      <td>-0.706656</td>\n",
              "      <td>-0.689891</td>\n",
              "      <td>-0.696226</td>\n",
              "      <td>-0.694412</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.658364</td>\n",
              "      <td>-0.654687</td>\n",
              "      <td>-0.656663</td>\n",
              "      <td>-0.664909</td>\n",
              "      <td>-0.661228</td>\n",
              "      <td>-0.662664</td>\n",
              "      <td>-0.660405</td>\n",
              "      <td>-0.666342</td>\n",
              "      <td>-0.662049</td>\n",
              "      <td>-0.658112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.053580</td>\n",
              "      <td>0.004223</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>-0.012687</td>\n",
              "      <td>-0.002991</td>\n",
              "      <td>-0.015451</td>\n",
              "      <td>-0.011694</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>-0.003435</td>\n",
              "      <td>-0.001606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002633</td>\n",
              "      <td>0.001498</td>\n",
              "      <td>-0.000798</td>\n",
              "      <td>-0.003280</td>\n",
              "      <td>-0.002778</td>\n",
              "      <td>-0.003044</td>\n",
              "      <td>-0.002424</td>\n",
              "      <td>-0.001132</td>\n",
              "      <td>-0.000940</td>\n",
              "      <td>0.006711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.691868</td>\n",
              "      <td>0.690616</td>\n",
              "      <td>0.691151</td>\n",
              "      <td>0.685165</td>\n",
              "      <td>0.687644</td>\n",
              "      <td>0.681655</td>\n",
              "      <td>0.674864</td>\n",
              "      <td>0.687978</td>\n",
              "      <td>0.682214</td>\n",
              "      <td>0.687811</td>\n",
              "      <td>...</td>\n",
              "      <td>0.673246</td>\n",
              "      <td>0.656682</td>\n",
              "      <td>0.657334</td>\n",
              "      <td>0.662245</td>\n",
              "      <td>0.658149</td>\n",
              "      <td>0.664583</td>\n",
              "      <td>0.671543</td>\n",
              "      <td>0.659681</td>\n",
              "      <td>0.656259</td>\n",
              "      <td>0.668834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.938376</td>\n",
              "      <td>4.819486</td>\n",
              "      <td>4.084691</td>\n",
              "      <td>4.201175</td>\n",
              "      <td>4.774795</td>\n",
              "      <td>4.030600</td>\n",
              "      <td>4.107842</td>\n",
              "      <td>4.296896</td>\n",
              "      <td>4.702594</td>\n",
              "      <td>4.241332</td>\n",
              "      <td>...</td>\n",
              "      <td>3.494462</td>\n",
              "      <td>3.918164</td>\n",
              "      <td>3.728241</td>\n",
              "      <td>3.732705</td>\n",
              "      <td>3.883194</td>\n",
              "      <td>3.874704</td>\n",
              "      <td>4.048236</td>\n",
              "      <td>3.966050</td>\n",
              "      <td>3.931646</td>\n",
              "      <td>4.196551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0             1             2             3             4    \\\n",
              "count  40000.000000  40000.000000  40000.000000  40000.000000  40000.000000   \n",
              "mean      -0.009969     -0.000861     -0.003661     -0.007749     -0.002877   \n",
              "std        1.111967      1.028025      1.030586      1.023116      1.022865   \n",
              "min       -4.683073     -4.085822     -4.398201     -4.227556     -4.171722   \n",
              "25%       -0.756994     -0.691476     -0.707846     -0.703444     -0.693633   \n",
              "50%       -0.053580      0.004223      0.000308     -0.012687     -0.002991   \n",
              "75%        0.691868      0.690616      0.691151      0.685165      0.687644   \n",
              "max        5.938376      4.819486      4.084691      4.201175      4.774795   \n",
              "\n",
              "                5             6             7             8             9    \\\n",
              "count  40000.000000  40000.000000  40000.000000  40000.000000  40000.000000   \n",
              "mean      -0.007710     -0.009757      0.000628     -0.006537     -0.003391   \n",
              "std        1.023433      1.025653      1.024842      1.022819      1.024262   \n",
              "min       -4.252212     -4.467492     -4.323473     -4.375755     -4.035621   \n",
              "25%       -0.704269     -0.706656     -0.689891     -0.696226     -0.694412   \n",
              "50%       -0.015451     -0.011694      0.002122     -0.003435     -0.001606   \n",
              "75%        0.681655      0.674864      0.687978      0.682214      0.687811   \n",
              "max        4.030600      4.107842      4.296896      4.702594      4.241332   \n",
              "\n",
              "           ...                140           141           142           143  \\\n",
              "count      ...       40000.000000  40000.000000  40000.000000  40000.000000   \n",
              "mean       ...           0.003258      0.000764      0.003336      0.000396   \n",
              "std        ...           0.982844      0.978328      0.980911      0.980949   \n",
              "min        ...          -3.837154     -4.022554     -4.210793     -4.591094   \n",
              "25%        ...          -0.658364     -0.654687     -0.656663     -0.664909   \n",
              "50%        ...           0.002633      0.001498     -0.000798     -0.003280   \n",
              "75%        ...           0.673246      0.656682      0.657334      0.662245   \n",
              "max        ...           3.494462      3.918164      3.728241      3.732705   \n",
              "\n",
              "                144           145           146           147           148  \\\n",
              "count  40000.000000  40000.000000  40000.000000  40000.000000  40000.000000   \n",
              "mean       0.000359      0.000831      0.004061     -0.003667     -0.002305   \n",
              "std        0.980259      0.978852      0.977869      0.982850      0.977271   \n",
              "min       -4.109285     -3.798605     -3.923197     -4.015625     -4.160880   \n",
              "25%       -0.661228     -0.662664     -0.660405     -0.666342     -0.662049   \n",
              "50%       -0.002778     -0.003044     -0.002424     -0.001132     -0.000940   \n",
              "75%        0.658149      0.664583      0.671543      0.659681      0.656259   \n",
              "max        3.883194      3.874704      4.048236      3.966050      3.931646   \n",
              "\n",
              "                149  \n",
              "count  40000.000000  \n",
              "mean       0.003330  \n",
              "std        0.978953  \n",
              "min       -3.855955  \n",
              "25%       -0.658112  \n",
              "50%        0.006711  \n",
              "75%        0.668834  \n",
              "max        4.196551  \n",
              "\n",
              "[8 rows x 150 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "metadata": {
        "id": "hWuLehhxEPoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "70cb23c1-7807-4381-c924-7001c0df4fb4"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "RFC = RandomForestClassifier()  \n",
        "             \n",
        "RFC.fit(X_train, y_train)  \n",
        "y_pred = RFC.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35945    48]\n",
            " [ 3947    60]]\n",
            "Accuracy score is 0.900125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kj0kc-CXbZYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZ2cFvaLE4Nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fb460399-99cf-41ae-fc41-972cc5605074"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35822    54]\n",
            " [ 4050    74]]\n",
            "Accuracy score is 0.8974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0jyQbif_E78E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "5510f461-38d1-4652-975e-02fb93151291"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35449   544]\n",
            " [ 2903  1104]]\n",
            "Accuracy score is 0.913825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xkEPPp3PLF9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "73ba261f-e60d-46b2-927e-563edbb9a672"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35367   509]\n",
            " [ 3020  1104]]\n",
            "Accuracy score is 0.911775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-f7nHUjRLMdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDLN61vhFVI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "f6b19d78-a8cc-4a9b-df2f-e2c8b10f8f1a"
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35867     9]\n",
            " [ 4058    66]]\n",
            "Accuracy score is 0.898325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-0mzF7necvTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "4223b799-718c-43a3-e8a0-d3a40e934e2c"
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35989     4]\n",
            " [ 3942    65]]\n",
            "Accuracy score is 0.90135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2uaDvSc9Nl_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e368e954-f0e8-4993-d591-c658b4c23546"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test) \n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35334   542]\n",
            " [ 2986  1138]]\n",
            "Accuracy score is 0.9118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9XL2t1sbEg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "087cf070-1d77-491a-9913-d2a56ba3a7e5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test) \n",
        "predictions = lda.predict_proba(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, lda.predict(X_test))\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, lda.predict(X_test)))\n",
        "predictions = lda.predict_proba(X_test)\n",
        "\n",
        "print(roc_auc_score(y_test, predictions[:,1]))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, predictions[:,1])\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35333   504]\n",
            " [ 2997  1166]]\n",
            "Accuracy score is 0.912475\n",
            "0.633011399446922\n",
            "0.633011399446922\n",
            "0.8652957527534239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hjqThKEZQT5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35333   504]\n",
        " [ 2997  1166]]\n",
        "Accuracy score is 0.912475\n",
        "0.633011399446922\n",
        "0.633011399446922\n",
        "0.8652957527534239"
      ]
    },
    {
      "metadata": {
        "id": "4RpRq3DxQckn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "5cde2e0c-270d-474e-a672-70eff619c9cd"
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = model.predict_proba(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35832     5]\n",
            " [ 4090    73]]\n",
            "Accuracy score is 0.897625\n",
            "0.5086979552861222\n",
            "0.5086979552861222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8gd91MSxWqpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35832     5]\n",
        " [ 4090    73]]\n",
        "Accuracy score is 0.897625\n",
        "0.5086979552861222\n",
        "0.5086979552861222"
      ]
    },
    {
      "metadata": {
        "id": "s1kUdo5PWsqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "4038d153-b9f5-472f-fa05-e557ee594349"
      },
      "cell_type": "code",
      "source": [
        "import sklearn.linear_model as lm\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "model = lm.LogisticRegression()\n",
        "\n",
        "a=model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = model.predict_proba(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35360   477]\n",
            " [ 3036  1127]]\n",
            "Accuracy score is 0.912175\n",
            "0.6287039830589609\n",
            "0.6287039830589609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Vhc8sPIW2TE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[[35360   477]\n",
        " [ 3036  1127]]\n",
        "Accuracy score is 0.912175\n",
        "0.6287039830589609\n",
        "0.6287039830589609"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nlv-Y2rAXGR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35360   477]\n",
        " [ 3036  1127]]\n",
        "Accuracy score is 0.912175\n",
        "0.6287039830589609\n",
        "0.6287039830589609"
      ]
    },
    {
      "metadata": {
        "id": "cfoePsCEZxOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "382ed8cd-e4d2-4c5d-da35-ff6f1af7e729"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "RFC = RandomForestClassifier()  \n",
        "             \n",
        "RFC.fit(X_train, y_train)  \n",
        "y_pred = RFC.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35889    51]\n",
            " [ 3998    62]]\n",
            "Accuracy score is 0.898775\n",
            "0.5069259521205294\n",
            "0.5069259521205294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pxZWxGIPXL9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rf_feature_importance(m,df):\n",
        "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
        "                       ).sort_values('imp', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ouYyT9Akhhnp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GPqriZJXYG5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a1b04064-9695-46c5-a8a9-2620ab98a44b"
      },
      "cell_type": "code",
      "source": [
        "fi = rf_feature_importance(RFC, X_train); fi[:30]"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cols</th>\n",
              "      <th>imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>0.011674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>139</td>\n",
              "      <td>0.009756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.009626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>80</td>\n",
              "      <td>0.008441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>110</td>\n",
              "      <td>0.008403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>109</td>\n",
              "      <td>0.008236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.008102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>0.008084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>166</td>\n",
              "      <td>0.007941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>174</td>\n",
              "      <td>0.007842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.007762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>146</td>\n",
              "      <td>0.007762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.007720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>190</td>\n",
              "      <td>0.007504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.007445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>0.007376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>76</td>\n",
              "      <td>0.007253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.007141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>0.007021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>133</td>\n",
              "      <td>0.006914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.006842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>0.006741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.006670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>0.006630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>78</td>\n",
              "      <td>0.006595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>165</td>\n",
              "      <td>0.006584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>179</td>\n",
              "      <td>0.006569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>0.006480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>0.006351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>170</td>\n",
              "      <td>0.006327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    cols       imp\n",
              "81    81  0.011674\n",
              "139  139  0.009756\n",
              "12    12  0.009626\n",
              "80    80  0.008441\n",
              "110  110  0.008403\n",
              "109  109  0.008236\n",
              "26    26  0.008102\n",
              "53    53  0.008084\n",
              "166  166  0.007941\n",
              "174  174  0.007842\n",
              "22    22  0.007762\n",
              "146  146  0.007762\n",
              "6      6  0.007720\n",
              "190  190  0.007504\n",
              "0      0  0.007445\n",
              "44    44  0.007376\n",
              "76    76  0.007253\n",
              "13    13  0.007141\n",
              "198  198  0.007021\n",
              "133  133  0.006914\n",
              "2      2  0.006842\n",
              "94    94  0.006741\n",
              "21    21  0.006670\n",
              "99    99  0.006630\n",
              "78    78  0.006595\n",
              "165  165  0.006584\n",
              "179  179  0.006569\n",
              "33    33  0.006480\n",
              "40    40  0.006351\n",
              "170  170  0.006327"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "metadata": {
        "id": "xgphLVbFcbKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "70fe2e94-5ec3-4c39-d482-7a74a8e4c66c"
      },
      "cell_type": "code",
      "source": [
        "fi.plot('cols', 'imp', figsize=(10,6), legend=False);"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAF0CAYAAAD2C+d2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEwaHXgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XuMlAM2mdMPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d831f3a-04c0-4efd-f6ad-d12fcb04d06e"
      },
      "cell_type": "code",
      "source": [
        "to_keep = fi[fi.imp>0.005].cols; len(to_keep)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "metadata": {
        "id": "4e-ZHiqUdtho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train2 = X_train[to_keep].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBdxwTOed1Ja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test2 = X_test[to_keep].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u6p2_0STefDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71063040-aa11-44e1-f294-988e4515e624"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {
        "id": "IpwLO_vreDbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "92dbcf07-1d40-4cf3-b82f-a095786a854c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train2, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test2) \n",
        "predictions = lda.predict_proba(X_test2)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35540   400]\n",
            " [ 3261   799]]\n",
            "Accuracy score is 0.908475\n",
            "0.5928341845056485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-01e94d77dbff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
            "\u001b[0;31mValueError\u001b[0m: X has 200 features per sample; expecting 71"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OPMX-iRMhJvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "472b0ac1-fb77-41d9-d4b3-32e9cd5ecd16"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "RFC = RandomForestClassifier()  \n",
        "             \n",
        "RFC.fit(X_train2, y_train)  \n",
        "y_pred = RFC.predict(X_test2)\n",
        "\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35851    89]\n",
            " [ 3934   126]]\n",
            "Accuracy score is 0.899425\n",
            "0.5142790666436398\n",
            "0.5142790666436398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_NjSmDGhrw4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logistic_feature_importance(m,df):\n",
        "    return pd.DataFrame({'cols':df.columns, 'imp':abs(m.coef_[0])}\n",
        "                       ).sort_values('imp', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cljgvuHUiEmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "dfe5e482-b3ba-451f-d054-f5a134ef07d0"
      },
      "cell_type": "code",
      "source": [
        "lfi=logistic_feature_importance(model,X_train); lfi[:30]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cols</th>\n",
              "      <th>imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>0.255369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>139</td>\n",
              "      <td>0.232759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.228867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>76</td>\n",
              "      <td>0.214066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.213014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>110</td>\n",
              "      <td>0.207541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.204904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>0.203433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>146</td>\n",
              "      <td>0.200756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>174</td>\n",
              "      <td>0.198823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.196476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.195150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>165</td>\n",
              "      <td>0.191218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>80</td>\n",
              "      <td>0.187960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>0.186087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>190</td>\n",
              "      <td>0.182117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>0.176318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.175539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>166</td>\n",
              "      <td>0.175404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.172527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>133</td>\n",
              "      <td>0.171845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.170079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>0.169035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>0.168370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>78</td>\n",
              "      <td>0.168160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>148</td>\n",
              "      <td>0.167037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>0.165429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>179</td>\n",
              "      <td>0.165092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>0.159642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>169</td>\n",
              "      <td>0.158698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    cols       imp\n",
              "81    81  0.255369\n",
              "139  139  0.232759\n",
              "6      6  0.228867\n",
              "76    76  0.214066\n",
              "12    12  0.213014\n",
              "110  110  0.207541\n",
              "21    21  0.204904\n",
              "53    53  0.203433\n",
              "146  146  0.200756\n",
              "174  174  0.198823\n",
              "22    22  0.196476\n",
              "26    26  0.195150\n",
              "165  165  0.191218\n",
              "80    80  0.187960\n",
              "99    99  0.186087\n",
              "190  190  0.182117\n",
              "34    34  0.176318\n",
              "13    13  0.175539\n",
              "166  166  0.175404\n",
              "0      0  0.172527\n",
              "133  133  0.171845\n",
              "2      2  0.170079\n",
              "44    44  0.169035\n",
              "198  198  0.168370\n",
              "78    78  0.168160\n",
              "148  148  0.167037\n",
              "40    40  0.165429\n",
              "179  179  0.165092\n",
              "94    94  0.159642\n",
              "169  169  0.158698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "metadata": {
        "id": "doBuID7Bi2lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3103cdd0-6fee-4135-8a9d-25df7359653f"
      },
      "cell_type": "code",
      "source": [
        "to_keep = lfi[lfi.imp>0.1].cols; len(to_keep)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "metadata": {
        "id": "cx6HVifIjMMa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train2 = X_train[to_keep].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U6IqeFbAjTll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test2 = X_test[to_keep].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a0wh0ILWjdrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "03168b6e-a496-428e-e0b2-d521785c48b7"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train2, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test2) \n",
        "predictions = lda.predict_proba(X_test2)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(auc(false_positive_rate, true_positive_rate))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35516   424]\n",
            " [ 3164   896]]\n",
            "Accuracy score is 0.9103\n",
            "0.6044461074971695\n",
            "0.6044461074971695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBZBwHKcjtUP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```[[35516   424]\n",
        " [ 3164   896]]\n",
        "Accuracy score is 0.9103\n",
        "0.6044461074971695\n",
        "0.6044461074971695\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mg2b9rjsjxvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "19a86585-5719-4d8b-b422-a09f45688a8b"
      },
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "lda = LDA(n_components=2)  \n",
        "lda.fit_transform(X_train, y_train)\n",
        "\n",
        "y_pred = lda.predict(X_test) \n",
        "predictions = lda.predict_proba(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "print(\"Area under ROC is \"+str(auc(false_positive_rate, true_positive_rate)))\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35484   445]\n",
            " [ 3157   914]]\n",
            "Accuracy score is 0.90995\n",
            "Area under ROC is 0.6060646615343934\n",
            "0.6060646615343934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "leAy7aTfLDO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35484   445]\n",
        " [ 3157   914]]\n",
        "Accuracy score is 0.90995\n",
        "Area under ROC is 0.6060646615343934 /X with PCA(100) scaled"
      ]
    },
    {
      "metadata": {
        "id": "RtEUv21PV4sm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35558   414]\n",
        " [ 3244   784]]\n",
        "Accuracy score is 0.90855\n",
        "Area under ROC is 0.5915642929163375 // LDA with PCA(150)"
      ]
    },
    {
      "metadata": {
        "id": "agtsKzBhKHyp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35870   203]\n",
        " [ 3588   339]]\n",
        "Accuracy score is 0.905225\n",
        "Area under ROC is 0.5403489808258896 //LDA X with PCA(100) no scaled"
      ]
    },
    {
      "metadata": {
        "id": "PCRPgstkB2t_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35448   516]\n",
        " [ 2914  1122]]\n",
        "Accuracy score is 0.91425\n",
        "Area under ROC is 0.6318251684125487 // X with scaling"
      ]
    },
    {
      "metadata": {
        "id": "52aZCl5C_1_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[[35484   526]\n",
        " [ 2849  1141]]\n",
        "Accuracy score is 0.915625\n",
        "Area under ROC is 0.6356789293422392\n",
        "0.6356789293422392 // LDA with no scaling full X (base)"
      ]
    },
    {
      "metadata": {
        "id": "40WDv1Y9Alef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bMBs2xoFtHd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "b5c956a9-e3ae-4af5-add9-2cde90fc6846"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA().fit(dx)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV2OddC4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WazueB5DGbZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab533cbd-ff00-4aca-e12e-f0bf2a3e1b5c"
      },
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=150)\n",
        "pca.fit(dx)\n",
        "dx = pca.transform(dx)\n",
        "dx.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "metadata": {
        "id": "ucLuq-P-M5Zs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ldaf(X_train, y_train, X_test, y_test):\n",
        "  print(X_test.shape)\n",
        "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "  from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "  from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "  import matplotlib.pyplot as plt\n",
        "  lda = LDA(n_components=2)  \n",
        "  lda.fit_transform(X_train, y_train)\n",
        "\n",
        "  y_pred = lda.predict(X_test) \n",
        "  predictions = lda.predict_proba(X_test)\n",
        "  print(confusion_matrix(y_test,y_pred))\n",
        "  print(\"Accuracy score is \"+str(accuracy_score(y_test,y_pred)))\n",
        "  false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
        "  print(\"Area under ROC is \"+str(auc(false_positive_rate, true_positive_rate)))\n",
        "  return auc(false_positive_rate, true_positive_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DQY7qe37OeEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "94c2a5f6-a198-4c5a-968d-b690e8aa7d98"
      },
      "cell_type": "code",
      "source": [
        "ldaf(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 150)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[35423   541]\n",
            " [ 2945  1091]]\n",
            "Accuracy score is 0.91285\n",
            "Area under ROC is 0.6276371625452123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6276371625452123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "FN2SmVUJXM-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run k-means where k=3\n",
        "from sklearn.cluster import KMeans\n",
        "# Initializing KMeans\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "# Fitting with inputs\n",
        "kmeans = kmeans.fit(dx)\n",
        "# Predicting the clusters\n",
        "labels = kmeans.predict(X)\n",
        "# Getting the cluster centers\n",
        "C = kmeans.cluster_centers_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}